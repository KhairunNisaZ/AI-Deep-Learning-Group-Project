{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1X1NSODqEVl0t7NmK4s2YRCGXrKLkaghc","timestamp":1686306596839},{"file_id":"1LqipFQtRK5LVgC3B8FJmCfnlKu2ZwuiN","timestamp":1686297082965},{"file_id":"1TUIMrla13MYIN-lALZLu6oepn2916frw","timestamp":1686229348858},{"file_id":"1AhpkW267sCsKeiCybqUg2CozOp3U7IY3","timestamp":1686227976678}],"mount_file_id":"1w_tQIk63G_pLyk8TS9pmkl2Lvy9rYeZk","authorship_tag":"ABX9TyNfGjm2NyN/zXjqKqfcTNo3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#AI Group Project ~ Deep Learning"],"metadata":{"id":"TDGt8sIfqV0C"}},{"cell_type":"markdown","source":["##Prediction of Pumpkin Seed Type\n","\n"],"metadata":{"id":"suCqrVQrqlbR"}},{"cell_type":"markdown","source":["Dataset ini berisi 2.500 data dan 13 features. Terdapat dua jenis biji labu, yaitu'Urgup_Sivrisi' dan 'Cercevelik' yang umumnya ditanam di daerah Urgup dan Karacaoren di Turki. Project ini dilakukan untuk dapat mengklasifikasi jenis biji labu dengan data-data yang telah ada. Dataset diambil dari link https://www.kaggle.com/datasets/muratkokludataset/pumpkin-seeds-dataset"],"metadata":{"id":"GPMDtkxdrXVe"}},{"cell_type":"markdown","source":["###Import Modules"],"metadata":{"id":"AxkdzSDbrFd2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GaQMpuHeyjXG"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import seaborn as sns\n","import re\n","from numpy import random\n","\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","import random\n","from random import seed\n","from random import randrange\n","from csv import reader\n","from math import sqrt\n","import csv\n","\n","\n"]},{"cell_type":"markdown","source":["###Load Dataset"],"metadata":{"id":"-Pfv2yHhrNUG"}},{"cell_type":"code","source":["pumpkin_data = pd.read_excel('/content/drive/MyDrive/Datasets/Pumpkin_Seeds_Dataset.xlsx')\n","pumpkin_data.tail(10)\n","\n","class_map = {'Çerçevelik': 1, 'Ürgüp Sivrisi':2}\n","pumpkin_data['Class'] = pumpkin_data['Class'].replace(class_map)\n","\n","df = pumpkin_data[['Area',\t'Perimeter',\t'Major_Axis_Length',\t'Minor_Axis_Length', 'Convex_Area',\t'Equiv_Diameter',\t'Eccentricity',\t'Solidity',\t'Extent',\t'Roundness',\t'Aspect_Ration',\t'Compactness',\t'Class']]\n","df.tail(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"iFe4JHTr3Qj_","executionInfo":{"status":"ok","timestamp":1686725355215,"user_tz":-420,"elapsed":603,"user":{"displayName":"SST Archange","userId":"00687597079602900259"}},"outputId":"cb34878a-cd1f-4921-d68a-91978c839da3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Convex_Area  \\\n","2490  51555    934.911           401.8321           164.7038        52013   \n","2491  69836   1010.605           396.6286           224.7918        70419   \n","2492  84236   1274.656           456.9323           237.1540        85248   \n","2493  58987    977.410           404.0779           186.3710        59518   \n","2494  79755   1146.431           470.3888           217.8296        80649   \n","2495  79637   1224.710           533.1513           190.4367        80381   \n","2496  69647   1084.318           462.9416           191.8210        70216   \n","2497  87994   1210.314           507.2200           222.1872        88702   \n","2498  80011   1182.947           501.9065           204.7531        80902   \n","2499  84934   1159.933           462.8951           234.5597        85781   \n","\n","      Equiv_Diameter  Eccentricity  Solidity  Extent  Roundness  \\\n","2490        256.2067        0.9121    0.9912  0.7187     0.7412   \n","2491        298.1911        0.8239    0.9917  0.6693     0.8593   \n","2492        327.4944        0.8548    0.9881  0.6104     0.6515   \n","2493        274.0522        0.8873    0.9911  0.7327     0.7759   \n","2494        318.6647        0.8863    0.9889  0.7175     0.7626   \n","2495        318.4289        0.9340    0.9907  0.4888     0.6672   \n","2496        297.7874        0.9101    0.9919  0.6002     0.7444   \n","2497        334.7199        0.8990    0.9920  0.7643     0.7549   \n","2498        319.1758        0.9130    0.9890  0.7374     0.7185   \n","2499        328.8485        0.8621    0.9901  0.7360     0.7933   \n","\n","      Aspect_Ration  Compactness  Class  \n","2490         2.4397       0.6376      2  \n","2491         1.7644       0.7518      2  \n","2492         1.9267       0.7167      2  \n","2493         2.1681       0.6782      2  \n","2494         2.1594       0.6774      2  \n","2495         2.7996       0.5973      2  \n","2496         2.4134       0.6433      2  \n","2497         2.2828       0.6599      2  \n","2498         2.4513       0.6359      2  \n","2499         1.9735       0.7104      2  "],"text/html":["\n","  <div id=\"df-b53e9188-2f4f-454d-8deb-12d371e544b7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area</th>\n","      <th>Perimeter</th>\n","      <th>Major_Axis_Length</th>\n","      <th>Minor_Axis_Length</th>\n","      <th>Convex_Area</th>\n","      <th>Equiv_Diameter</th>\n","      <th>Eccentricity</th>\n","      <th>Solidity</th>\n","      <th>Extent</th>\n","      <th>Roundness</th>\n","      <th>Aspect_Ration</th>\n","      <th>Compactness</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2490</th>\n","      <td>51555</td>\n","      <td>934.911</td>\n","      <td>401.8321</td>\n","      <td>164.7038</td>\n","      <td>52013</td>\n","      <td>256.2067</td>\n","      <td>0.9121</td>\n","      <td>0.9912</td>\n","      <td>0.7187</td>\n","      <td>0.7412</td>\n","      <td>2.4397</td>\n","      <td>0.6376</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2491</th>\n","      <td>69836</td>\n","      <td>1010.605</td>\n","      <td>396.6286</td>\n","      <td>224.7918</td>\n","      <td>70419</td>\n","      <td>298.1911</td>\n","      <td>0.8239</td>\n","      <td>0.9917</td>\n","      <td>0.6693</td>\n","      <td>0.8593</td>\n","      <td>1.7644</td>\n","      <td>0.7518</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2492</th>\n","      <td>84236</td>\n","      <td>1274.656</td>\n","      <td>456.9323</td>\n","      <td>237.1540</td>\n","      <td>85248</td>\n","      <td>327.4944</td>\n","      <td>0.8548</td>\n","      <td>0.9881</td>\n","      <td>0.6104</td>\n","      <td>0.6515</td>\n","      <td>1.9267</td>\n","      <td>0.7167</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2493</th>\n","      <td>58987</td>\n","      <td>977.410</td>\n","      <td>404.0779</td>\n","      <td>186.3710</td>\n","      <td>59518</td>\n","      <td>274.0522</td>\n","      <td>0.8873</td>\n","      <td>0.9911</td>\n","      <td>0.7327</td>\n","      <td>0.7759</td>\n","      <td>2.1681</td>\n","      <td>0.6782</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2494</th>\n","      <td>79755</td>\n","      <td>1146.431</td>\n","      <td>470.3888</td>\n","      <td>217.8296</td>\n","      <td>80649</td>\n","      <td>318.6647</td>\n","      <td>0.8863</td>\n","      <td>0.9889</td>\n","      <td>0.7175</td>\n","      <td>0.7626</td>\n","      <td>2.1594</td>\n","      <td>0.6774</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2495</th>\n","      <td>79637</td>\n","      <td>1224.710</td>\n","      <td>533.1513</td>\n","      <td>190.4367</td>\n","      <td>80381</td>\n","      <td>318.4289</td>\n","      <td>0.9340</td>\n","      <td>0.9907</td>\n","      <td>0.4888</td>\n","      <td>0.6672</td>\n","      <td>2.7996</td>\n","      <td>0.5973</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2496</th>\n","      <td>69647</td>\n","      <td>1084.318</td>\n","      <td>462.9416</td>\n","      <td>191.8210</td>\n","      <td>70216</td>\n","      <td>297.7874</td>\n","      <td>0.9101</td>\n","      <td>0.9919</td>\n","      <td>0.6002</td>\n","      <td>0.7444</td>\n","      <td>2.4134</td>\n","      <td>0.6433</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2497</th>\n","      <td>87994</td>\n","      <td>1210.314</td>\n","      <td>507.2200</td>\n","      <td>222.1872</td>\n","      <td>88702</td>\n","      <td>334.7199</td>\n","      <td>0.8990</td>\n","      <td>0.9920</td>\n","      <td>0.7643</td>\n","      <td>0.7549</td>\n","      <td>2.2828</td>\n","      <td>0.6599</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2498</th>\n","      <td>80011</td>\n","      <td>1182.947</td>\n","      <td>501.9065</td>\n","      <td>204.7531</td>\n","      <td>80902</td>\n","      <td>319.1758</td>\n","      <td>0.9130</td>\n","      <td>0.9890</td>\n","      <td>0.7374</td>\n","      <td>0.7185</td>\n","      <td>2.4513</td>\n","      <td>0.6359</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2499</th>\n","      <td>84934</td>\n","      <td>1159.933</td>\n","      <td>462.8951</td>\n","      <td>234.5597</td>\n","      <td>85781</td>\n","      <td>328.8485</td>\n","      <td>0.8621</td>\n","      <td>0.9901</td>\n","      <td>0.7360</td>\n","      <td>0.7933</td>\n","      <td>1.9735</td>\n","      <td>0.7104</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b53e9188-2f4f-454d-8deb-12d371e544b7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b53e9188-2f4f-454d-8deb-12d371e544b7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b53e9188-2f4f-454d-8deb-12d371e544b7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["###About The Dataset"],"metadata":{"id":"3-BsSJstHGat"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"-RIZgKnDvGuV","executionInfo":{"status":"ok","timestamp":1686722332212,"user_tz":-420,"elapsed":24,"user":{"displayName":"SST Archange","userId":"00687597079602900259"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a2e114b4-7858-4ea7-95a5-d8b13f87794a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2500 entries, 0 to 2499\n","Data columns (total 13 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   Area               2500 non-null   int64  \n"," 1   Perimeter          2500 non-null   float64\n"," 2   Major_Axis_Length  2500 non-null   float64\n"," 3   Minor_Axis_Length  2500 non-null   float64\n"," 4   Convex_Area        2500 non-null   int64  \n"," 5   Equiv_Diameter     2500 non-null   float64\n"," 6   Eccentricity       2500 non-null   float64\n"," 7   Solidity           2500 non-null   float64\n"," 8   Extent             2500 non-null   float64\n"," 9   Roundness          2500 non-null   float64\n"," 10  Aspect_Ration      2500 non-null   float64\n"," 11  Compactness        2500 non-null   float64\n"," 12  Class              2500 non-null   int64  \n","dtypes: float64(10), int64(3)\n","memory usage: 254.0 KB\n"]}]},{"cell_type":"markdown","source":["###Split Dataset"],"metadata":{"id":"tl-s_D4PHM24"}},{"cell_type":"code","source":["X = df[['Area',\t'Perimeter',\t'Major_Axis_Length',\t'Minor_Axis_Length', 'Convex_Area',\t'Equiv_Diameter',\t'Eccentricity',\t'Solidity',\t'Extent',\t'Roundness',\t'Aspect_Ration',\t'Compactness']].values\n","y = df['Class'].values"],"metadata":{"id":"j_8lH6YWfJCL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Split Train Test Data"],"metadata":{"id":"lvnAfRY4fD5i"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2)"],"metadata":{"id":"oYH3hOkVggxg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Decision Tree"],"metadata":{"id":"rbYKj5MKjHdF"}},{"cell_type":"code","source":["class Node():\n","    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n","        ''' constructor '''\n","\n","        # for decision node\n","        self.feature_index = feature_index\n","        self.threshold = threshold\n","        self.left = left\n","        self.right = right\n","        self.info_gain = info_gain\n","\n","        # for leaf node\n","        self.value = value\n","\n","class DecisionTreeClassifier():\n","    def __init__(self, min_samples_split=2, max_depth=2):\n","        ''' constructor '''\n","\n","        # initialize the root of the tree\n","        self.root = None\n","\n","        # stopping conditions\n","        self.min_samples_split = min_samples_split\n","        self.max_depth = max_depth\n","\n","    def build_tree(self, dataset, curr_depth=0):\n","        ''' recursive function to build the tree '''\n","\n","        X, Y = dataset[:,:-1], dataset[:,-1]\n","        num_samples, num_features = np.shape(X)\n","\n","        # split until stopping conditions are met\n","        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n","            # find the best split\n","            best_split = self.get_best_split(dataset, num_samples, num_features)\n","            # check if information gain is positive\n","            if best_split[\"info_gain\"]>0:\n","                # recur left\n","                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n","                # recur right\n","                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n","                # return decision node\n","                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n","                            left_subtree, right_subtree, best_split[\"info_gain\"])\n","\n","        # compute leaf node\n","        leaf_value = self.calculate_leaf_value(Y)\n","        # return leaf node\n","        return Node(value=leaf_value)\n","\n","    def get_best_split(self, dataset, num_samples, num_features):\n","        ''' function to find the best split '''\n","\n","        # dictionary to store the best split\n","        best_split = {}\n","        max_info_gain = -float(\"inf\")\n","\n","        # loop over all the features\n","        for feature_index in range(num_features):\n","            feature_values = dataset[:, feature_index]\n","            possible_thresholds = np.unique(feature_values)\n","            # loop over all the feature values present in the data\n","            for threshold in possible_thresholds:\n","                # get current split\n","                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n","                # check if childs are not null\n","                if len(dataset_left)>0 and len(dataset_right)>0:\n","                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n","                    # compute information gain\n","                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n","                    # update the best split if needed\n","                    if curr_info_gain>max_info_gain:\n","                        best_split[\"feature_index\"] = feature_index\n","                        best_split[\"threshold\"] = threshold\n","                        best_split[\"dataset_left\"] = dataset_left\n","                        best_split[\"dataset_right\"] = dataset_right\n","                        best_split[\"info_gain\"] = curr_info_gain\n","                        max_info_gain = curr_info_gain\n","\n","        # return best split\n","        return best_split\n","\n","    def split(self, dataset, feature_index, threshold):\n","        ''' function to split the data '''\n","\n","        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n","        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n","        return dataset_left, dataset_right\n","\n","    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n","        ''' function to compute information gain '''\n","\n","        weight_l = len(l_child) / len(parent)\n","        weight_r = len(r_child) / len(parent)\n","        if mode==\"gini\":\n","            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n","        else:\n","            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n","        return gain\n","\n","    def entropy(self, y):\n","        ''' function to compute entropy '''\n","\n","        class_labels = np.unique(y)\n","        entropy = 0\n","        for cls in class_labels:\n","            p_cls = len(y[y == cls]) / len(y)\n","            entropy += -p_cls * np.log2(p_cls)\n","        return entropy\n","\n","    def gini_index(self, y):\n","        ''' function to compute gini index '''\n","\n","        class_labels = np.unique(y)\n","        gini = 0\n","        for cls in class_labels:\n","            p_cls = len(y[y == cls]) / len(y)\n","            gini += p_cls**2\n","        return 1 - gini\n","\n","    def calculate_leaf_value(self, Y):\n","        ''' function to compute leaf node '''\n","\n","        Y = list(Y)\n","        return max(Y, key=Y.count)\n","\n","    def print_tree(self, tree=None, indent=\" \"):\n","        ''' function to print the tree '''\n","\n","        if not tree:\n","            tree = self.root\n","\n","        if tree.value is not None:\n","            print(tree.value)\n","\n","        else:\n","            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n","            print(\"%sleft:\" % (indent), end=\"\")\n","            self.print_tree(tree.left, indent + indent)\n","            print(\"%sright:\" % (indent), end=\"\")\n","            self.print_tree(tree.right, indent + indent)\n","\n","    def fit(self, X, Y):\n","        ''' function to train the tree '''\n","\n","        dataset = np.concatenate((X, Y), axis=1)\n","        self.root = self.build_tree(dataset)\n","\n","    def predict(self, X):\n","        ''' function to predict new dataset '''\n","\n","        preditions = [self.make_prediction(x, self.root) for x in X]\n","        return preditions\n","\n","    def make_prediction(self, x, tree):\n","        ''' function to predict a single data point '''\n","\n","        if tree.value!=None: return tree.value\n","        feature_val = x[tree.feature_index]\n","        if feature_val<=tree.threshold:\n","            return self.make_prediction(x, tree.left)\n","        else:\n","            return self.make_prediction(x, tree.right)"],"metadata":{"id":"sdwLViKUxJAO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = y_train.reshape(-1,1)"],"metadata":{"id":"WIsoOKuQ3iSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(y_train))\n","print(type(X_train))\n","print(y_train.shape)\n","print(X_train.shape)"],"metadata":{"id":"BsE4dI-J4IFA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686723724940,"user_tz":-420,"elapsed":441,"user":{"displayName":"SST Archange","userId":"00687597079602900259"}},"outputId":"19e6948b-9db7-4db9-c9df-5e612f7aafb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n","<class 'numpy.ndarray'>\n","(2000,)\n","(2000, 12)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","\n","# Initialize k-fold cross-validation\n","k = 5\n","kf = KFold(n_splits=k, shuffle=True)\n","\n","iteration_accuracy = []\n","for x in range(5):\n","# Perform k-fold cross-validation\n","  accuracy_scores = []\n","\n","  for train_index, val_index in kf.split(X):\n","      X_train, X_val = X[train_index], X[val_index]\n","      y_train, y_val = y[train_index], y[val_index]\n","\n","      # Ensure the dimensions of X and Y match\n","      if len(y_train.shape) == 1:\n","          y_train = y_train.reshape(-1, 1)\n","\n","      # Create a new instance of the DecisionTreeClassifier\n","      dt = DecisionTreeClassifier()\n","\n","      # Train the decision tree on the training set\n","      dt.fit(X_train, y_train)\n","\n","      # Make predictions on the validation set\n","      y_pred = dt.predict(X_val)\n","\n","      # Calculate the accuracy\n","      accuracy = np.sum(y_pred == y_val) / len(y_val)\n","      accuracy_scores.append(accuracy)\n","\n","  # Calculate the average accuracy across all folds\n","  average_accuracy = np.mean(accuracy_scores)\n","\n","  # Print the average accuracy\n","  print(f\"Average Accuracy run[{x}]: {average_accuracy}\")\n","\n","  iteration_accuracy.append(average_accuracy)\n","\n","print(\"Average Accuracy:\", np.mean(iteration_accuracy))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zmKLEJil3qd","executionInfo":{"status":"ok","timestamp":1686727424197,"user_tz":-420,"elapsed":2055977,"user":{"displayName":"SST Archange","userId":"00687597079602900259"}},"outputId":"be6cd145-9520-41f6-dfb4-af79f5958f57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Accuracy run[0]: 0.8708\n","Average Accuracy run[1]: 0.8695999999999999\n","Average Accuracy run[2]: 0.8695999999999999\n","Average Accuracy run[3]: 0.8712\n","Average Accuracy run[4]: 0.8704000000000001\n","Average Accuracy: 0.8703199999999999\n"]}]},{"cell_type":"code","source":["# Accuracy sebelum Feature Selection dan Data Augmentation\n","\n","# DOCUMENTATION result on June 14th 2:23 PM execution time: 34m 15s\n","# Average Accuracy run[0]: 0.8708\n","# Average Accuracy run[1]: 0.8696\n","# Average Accuracy run[2]: 0.8696\n","# Average Accuracy run[3]: 0.8712\n","# Average Accuracy run[4]: 0.8704\n","# Average Total: 0.8703199999999999"],"metadata":{"id":"HqOx26SjyjgZ"},"execution_count":null,"outputs":[]}]}